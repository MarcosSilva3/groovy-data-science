{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Processing\n",
    "\n",
    "> **_NOTE:_** The examples may take a little while to run as they download the models each time.\n",
    "\n",
    "## Language detection\n",
    "\n",
    "We'll use [Apache OpenNLP](https://opennlp.apache.org/) to detect the likely language for some fragments of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c054b1-faea-497b-985a-1343e058c0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.opennlp opennlp-tools 1.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import opennlp.tools.langdetect.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spa, fra, bul, dan]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base     = 'http://apache.forsale.plus/opennlp/models'\n",
    "url      = \"$base/langdetect/1.8.3/langdetect-183.bin\"\n",
    "model    = new LanguageDetectorModel(new URL(url))\n",
    "detector = new LanguageDetectorME(model)\n",
    "\n",
    "['Bienvenido a Madrid', 'Bienvenue à Paris',\n",
    " 'Добре дошли в София', 'Velkommen til København'].collect {\n",
    "    t -> detector.predictLanguage(t).lang\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Detection\n",
    "\n",
    "OpenNLP also supports sentence detection. We load the trained sentence detection model for English and use that to process some text. Even though the text has 28 full stops, only 4 of them are associated with the end of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The most referenced scientific paper of all time is \"Protein measurement with the\n",
       "Folin phenol reagent\" by Lowry, O. H., Rosebrough, N. J., Farr, A. L. & Randall,\n",
       "R. J. and was published in the J. BioChem. in 1951.\n",
       "\n",
       "It describes a method for\n",
       "measuring the amount of protein (even as small as 0.2 γ, were γ is the specific\n",
       "weight) in solutions and has been cited over 300,000 times and can be found here:\n",
       "https://www.jbc.org/content/193/1/265.full.pdf.\n",
       "\n",
       "Dr. Lowry completed\n",
       "two doctoral degrees under an M.D.-Ph.D. program from the University of Chicago\n",
       "before moving to Harvard under A. Baird Hastings.\n",
       "\n",
       "He was also the H.O.D of\n",
       "Pharmacology at Washington University in St. Louis for 29 years."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import opennlp.tools.sentdetect.*\n",
    "\n",
    "def text = '''\n",
    "The most referenced scientific paper of all time is \"Protein measurement with the\n",
    "Folin phenol reagent\" by Lowry, O. H., Rosebrough, N. J., Farr, A. L. & Randall,\n",
    "R. J. and was published in the J. BioChem. in 1951. It describes a method for\n",
    "measuring the amount of protein (even as small as 0.2 γ, were γ is the specific\n",
    "weight) in solutions and has been cited over 300,000 times and can be found here:\n",
    "https://www.jbc.org/content/193/1/265.full.pdf. Dr. Lowry completed\n",
    "two doctoral degrees under an M.D.-Ph.D. program from the University of Chicago\n",
    "before moving to Harvard under A. Baird Hastings. He was also the H.O.D of\n",
    "Pharmacology at Washington University in St. Louis for 29 years.\n",
    "'''\n",
    "\n",
    "base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "url      = \"$base/en-sent.bin\"\n",
    "\n",
    "def model = new SentenceModel(new URL(url))\n",
    "def detector = new SentenceDetectorME(model)\n",
    "def sentences = detector.sentDetect(text)\n",
    "assert text.count('.') == 28\n",
    "assert sentences.size() == 4\n",
    "sentences.join('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Detection\n",
    "\n",
    "Sometimes when analysing text we want to search for meaningful entities such as the dates, locations, names of people, etc. The following example uses OpenNLP. It has numerous named entity models which select such aspects individually. We'll use 5 English-language models: person, money, date, time, and location, but there are [other models and models for some other languages](http://opennlp.sourceforge.net/models-1.5/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading person ...\n",
      "Loading money ...\n",
      "Loading date ...\n",
      "Loading time ...\n",
      "Loading location ...\n",
      "A commit by person(Daniel Sun) on date(December 6, 2020) improved Groovy 4's language integrated query.\n",
      "A commit by person(Daniel) on Sun. date(December 6, 2020) improved Groovy 4's language integrated query.\n",
      "The Groovy in Action book by person(Dierk Koenig) et. al. is a bargain at money($50), or indeed any price.\n",
      "The conference wrapped up date(yesterday) at time(5:30 p.m.) in location(Copenhagen), location(Denmark).\n",
      "I saw Ms. person(May Smith) waving to person(June Jones).\n",
      "The parcel was passed from date(May to June).\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.namefind.*\n",
    "import opennlp.tools.tokenize.SimpleTokenizer\n",
    "import opennlp.tools.util.Span\n",
    "\n",
    "String[] sentences = [\n",
    "    \"A commit by Daniel Sun on December 6, 2020 improved Groovy 4's language integrated query.\",\n",
    "    \"A commit by Daniel on Sun. December 6, 2020 improved Groovy 4's language integrated query.\",\n",
    "    'The Groovy in Action book by Dierk Koenig et. al. is a bargain at $50, or indeed any price.',\n",
    "    'The conference wrapped up yesterday at 5:30 p.m. in Copenhagen, Denmark.',\n",
    "    'I saw Ms. May Smith waving to June Jones.',\n",
    "    'The parcel was passed from May to June.'\n",
    "]\n",
    "\n",
    "def base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "def modelNames = ['person', 'money', 'date', 'time', 'location']\n",
    "def finders = modelNames.collect{\n",
    "    println \"Loading $it ...\"\n",
    "    new NameFinderME(new TokenNameFinderModel(new URL((\"$base/en-ner-${it}.bin\"))))\n",
    "}\n",
    "\n",
    "def tokenizer = SimpleTokenizer.INSTANCE\n",
    "sentences.each { sentence ->\n",
    "    String[] tokens = tokenizer.tokenize(sentence)\n",
    "    Span[] tokenSpans = tokenizer.tokenizePos(sentence)\n",
    "    def entityText = [:]\n",
    "    def entityPos = [:]\n",
    "    finders.indices.each {fi ->\n",
    "        // could be made smarter by looking at probabilities and overlapping spans\n",
    "        Span[] spans = finders[fi].find(tokens)\n",
    "        spans.each{span ->\n",
    "            def se = span.start..<span.end\n",
    "            def pos = (tokenSpans[se.from].start)..<(tokenSpans[se.to].end)\n",
    "            entityPos[span.start] = pos\n",
    "            entityText[span.start] = \"$span.type(${sentence[pos]})\"\n",
    "        }\n",
    "    }\n",
    "    entityPos.keySet().toList().reverseEach {\n",
    "        def pos = entityPos[it]\n",
    "        def (from, to) = [pos.from, pos.to + 1]\n",
    "        sentence = sentence[0..<from] + entityText[it] + sentence[to..-1]\n",
    "    }\n",
    "    println sentence\n",
    "}\n",
    "OutputCell.HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech (POS) Detection\n",
    "\n",
    "Parts of speech (POS) detection tags words as nouns, verbs and other [parts-of-speed](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n",
    "Some of the common tags are:\n",
    "\n",
    "| Tag | Meaning |\n",
    "| --- | --- |\n",
    "| CC | coordinating conjunction |\n",
    "| CD | cardinal number |\n",
    "| DT | determiner |\n",
    "| IN | preposition or subordinating conjunction |\n",
    "| JJ | adjective |\n",
    "| JJR | adjective, comparative |\n",
    "| NN | noun, singular or mass |\n",
    "| NNS | noun, plural |\n",
    "| NNP | proper noun, singular |\n",
    "| POS | possessive ending |\n",
    "| PRP | personal pronoun |\n",
    "| PRP$ | possessive pronoun |\n",
    "| RB | adverb |\n",
    "| TO | the word \"to\" |\n",
    "| VB | verb, base form |\n",
    "| VBD | verb, past tense |\n",
    "| VBZ | verb, third person singular present |\n",
    "\n",
    "Here, we use OpenNLP's POS detection capabilities to detect the parts of speech for a nyumber of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP(Paul) VBZ(has) CD(two) NNS(sisters) , NNP(Maree) CC(and) NNP(Christine) .\n",
      "PRP$(His) NN(bark) VBD(was) RB(much) JJR(worse) IN(than) PRP$(his) NN(bite)\n",
      "VB(Turn) IN(on) DT(the) NNS(lights) TO(to) DT(the) NN(master) NN(bedroom)\n",
      "NN(Light) POS(') NN(em) DT(all) IN(up)\n",
      "VB(Make) PRP(it) JJ(dark) NN(downstairs)\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.postag.*\n",
    "import opennlp.tools.tokenize.SimpleTokenizer\n",
    "\n",
    "def base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "def sentences = [\n",
    "    'Paul has two sisters, Maree and Christine.',\n",
    "    'His bark was much worse than his bite',\n",
    "    'Turn on the lights to the master bedroom',\n",
    "    \"Light 'em all up\",\n",
    "    'Make it dark downstairs'\n",
    "]\n",
    "def model = new POSModel(new URL((\"$base/en-pos-maxent.bin\")))\n",
    "def posTagger = new POSTaggerME(model)\n",
    "def tokenizer = SimpleTokenizer.INSTANCE\n",
    "sentences.each {\n",
    "    String[] tokens = tokenizer.tokenize(it)\n",
    "    String[] tags = posTagger.tag(tokens)\n",
    "    println tokens.indices.collect{tags[it] == tokens[it] ? tags[it] : \"${tags[it]}(${tokens[it]})\" }.join(' ')\n",
    "}\n",
    "OutputCell.HIDDEN"
   ]
  },
  {
      "metadata": {
      },
      "cell_type": "markdown",
      "source": "## Sentiment analysis\n\nSentiment analysis attempts to categorize samples according to\nsome categories of interest, e.g.&nbsp;is a movie review\n(or a tweet, or some other social media comment)\npredominantly positive or negative.\n\nFirst we add a few imports:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%import opennlp.tools.doccat.DoccatFactory\n%import opennlp.tools.doccat.DocumentCategorizerME\n%import opennlp.tools.doccat.DocumentSampleStream\n%import opennlp.tools.util.CollectionObjectStream\n%import opennlp.tools.util.TrainingParameters",
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "metadata": {
      },
      "cell_type": "markdown",
      "source": "We can train up our model as follows:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def datasets = [\n        positive: \"../resources/rt-polarity.pos\",\n        negative: \"../resources/rt-polarity.neg\"\n]\n\n// OpenNLP is expecting one dataset with each line containing the category as the first term\ndef trainingCollection = datasets.collect { k, v ->\n    new File(v).readLines().collect{\"$k $it\".toString() }\n}.sum()\n\ndef trainingStream = new CollectionObjectStream(trainingCollection)\ndef sampleStream = new DocumentSampleStream(trainingStream)\ndef trainingParams = new TrainingParameters()\n\nmodel = DocumentCategorizerME.train('en', sampleStream, trainingParams, new DoccatFactory())",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Indexing events with TwoPass using cutoff of 5\n\n\tComputing event counts...  done. 10661 events\n\tIndexing...  Dropped event positive:[bow=spiderman, bow=rocks]\nDropped event negative:[bow=crummy]\ndone.\nSorting and merging events... done. Reduced 10659 events to 10647.\nDone indexing in 0.60 s.\nIncorporating indexed data for training...  \ndone.\n\tNumber of Event Tokens: 10647\n\t    Number of Outcomes: 2\n\t  Number of Predicates: 4473\n...done.\nComputing model parameters ...\nPerforming 100 iterations.\n  1:  ... loglikelihood=-7388.2557975896625\t0.4999530912843606\n  2:  ... loglikelihood=-7119.099404820946\t0.8399474622384839\n  3:  ... loglikelihood=-6877.278337067684\t0.8410732714138287\n  4:  ... loglikelihood=-6659.412022621164\t0.8433248897645182\n  5:  ... loglikelihood=-6462.486601121386\t0.8453888732526503\n  6:  ... loglikelihood=-6283.85696625181\t0.8470775870156675\n  7:  ... loglikelihood=-6121.226751836608\t0.8489539356412421\n  8:  ... loglikelihood=-5972.615747259465\t0.8498921099540294\n  9:  ... loglikelihood=-5836.322399524087\t0.851768458579604\n 10:  ... loglikelihood=-5710.886329532325\t0.8526128154611127\n 11:  ... loglikelihood=-5595.053537651803\t0.8539262594990149\n 12:  ... loglikelihood=-5487.7454678850945\t0.8552397035369171\n 13:  ... loglikelihood=-5388.032213212508\t0.8576789567501641\n 14:  ... loglikelihood=-5295.109677308437\t0.858429496200394\n 15:  ... loglikelihood=-5208.28029548722\t0.8593676705131813\n 16:  ... loglikelihood=-5126.936848785139\t0.8601182099634112\n 17:  ... loglikelihood=-5050.548910707523\t0.8615254714325922\n 18:  ... loglikelihood=-4978.651506472843\t0.8628389154704944\n 19:  ... loglikelihood=-4910.835617668545\t0.8638709072145605\n 20:  ... loglikelihood=-4846.740219744823\t0.8643399943709541\n 21:  ... loglikelihood=-4786.045590334068\t0.8649967163899053\n 22:  ... loglikelihood=-4728.46767086545\t0.8655596209775777\n 23:  ... loglikelihood=-4673.753301889446\t0.8667792475842011\n 24:  ... loglikelihood=-4621.676184301174\t0.8677174218969884\n 25:  ... loglikelihood=-4572.033444945831\t0.8679050567595459\n 26:  ... loglikelihood=-4524.642706697396\t0.868937048503612\n 27:  ... loglikelihood=-4479.33958078711\t0.8694061356600056\n 28:  ... loglikelihood=-4435.975513597663\t0.8704381274040717\n 29:  ... loglikelihood=-4394.415931929246\t0.8715639365794164\n 30:  ... loglikelihood=-4354.538640366532\t0.8718453888732527\n 31:  ... loglikelihood=-4316.232432244363\t0.8720330237358102\n 32:  ... loglikelihood=-4279.395882153619\t0.8730650154798761\n 33:  ... loglikelihood=-4243.936293214623\t0.8736279200675485\n 34:  ... loglikelihood=-4209.768776694725\t0.8745660943803358\n 35:  ... loglikelihood=-4176.815445132658\t0.8749413641054508\n 36:  ... loglikelihood=-4145.004703097989\t0.8759733558495169\n 37:  ... loglikelihood=-4114.270622172446\t0.8768177127310254\n 38:  ... loglikelihood=-4084.552388783994\t0.8771929824561403\n 39:  ... loglikelihood=-4055.793815231077\t0.8774744347499766\n 40:  ... loglikelihood=-4027.9429056586423\t0.8782249742002064\n 41:  ... loglikelihood=-4000.9514699454594\t0.8786002439253213\n 42:  ... loglikelihood=-3974.774779466685\t0.879069331081715\n 43:  ... loglikelihood=-3949.3712595451443\t0.880101322825781\n 44:  ... loglikelihood=-3924.7022141221205\t0.8808518622760109\n 45:  ... loglikelihood=-3900.731578787158\t0.8812271320011258\n 46:  ... loglikelihood=-3877.4256988240286\t0.8814147668636833\n 47:  ... loglikelihood=-3854.753129370631\t0.8824467586077493\n 48:  ... loglikelihood=-3832.6844551690137\t0.882540576039028\n 49:  ... loglikelihood=-3811.1921277032247\t0.8833849329205367\n 50:  ... loglikelihood=-3790.25031780181\t0.883947837508209\n 51:  ... loglikelihood=-3769.834782018944\t0.8841354723707665\n 52:  ... loglikelihood=-3749.922741316452\t0.8845107420958814\n 53:  ... loglikelihood=-3730.492770745267\t0.884979829252275\n 54:  ... loglikelihood=-3711.5246989809048\t0.8854489164086687\n 55:  ... loglikelihood=-3692.999516701024\t0.8854489164086687\n 56:  ... loglikelihood=-3674.899292910189\t0.8857303687025049\n 57:  ... loglikelihood=-3657.2070984189922\t0.8861056384276198\n 58:  ... loglikelihood=-3639.9069357735125\t0.8861994558588986\n 59:  ... loglikelihood=-3622.983675009304\t0.886387090721456\n 60:  ... loglikelihood=-3606.4229946725127\t0.8866685430152922\n 61:  ... loglikelihood=-3590.2113276104915\t0.8871376301716859\n 62:  ... loglikelihood=-3574.3358110879963\t0.8872314476029647\n 63:  ... loglikelihood=-3558.784240830474\t0.8873252650342434\n 64:  ... loglikelihood=-3543.5450286388477\t0.8876067173280796\n 65:  ... loglikelihood=-3528.6071632551793\t0.8880758044844732\n 66:  ... loglikelihood=-3513.9601741917195\t0.8882634393470307\n 67:  ... loglikelihood=-3499.5940982645025\t0.8883572567783095\n 68:  ... loglikelihood=-3485.4994485984716\t0.8885448916408669\n 69:  ... loglikelihood=-3471.667185892464\t0.8889201613659818\n 70:  ... loglikelihood=-3458.088691754974\t0.8889201613659818\n 71:  ... loglikelihood=-3444.755743937475\t0.889201613659818\n 72:  ... loglikelihood=-3431.660493309746\t0.8892954310910968\n 73:  ... loglikelihood=-3418.795442435364\t0.8895768833849329\n 74:  ... loglikelihood=-3406.1534256191035\t0.8896707008162117\n 75:  ... loglikelihood=-3393.7275903089762\t0.8903274228351628\n 76:  ... loglikelihood=-3381.511379746786\t0.8907026925602777\n 77:  ... loglikelihood=-3369.4985167704194\t0.8909841448541139\n 78:  ... loglikelihood=-3357.6829886788296\t0.8912655971479501\n 79:  ... loglikelihood=-3346.0590330795194\t0.8914532320105075\n 80:  ... loglikelihood=-3334.6211246447506\t0.891640866873065\n 81:  ... loglikelihood=-3323.3639627083585\t0.8924852237545736\n 82:  ... loglikelihood=-3312.2824596420205\t0.8927666760484098\n 83:  ... loglikelihood=-3301.3717299536543\t0.893048128342246\n 84:  ... loglikelihood=-3290.627080056442\t0.8936110329299184\n 85:  ... loglikelihood=-3280.0439986603947\t0.8939863026550333\n 86:  ... loglikelihood=-3269.6181477424216\t0.8946430246739844\n 87:  ... loglikelihood=-3259.345354054799\t0.8952059292616568\n 88:  ... loglikelihood=-3249.2216011346945\t0.895487381555493\n 89:  ... loglikelihood=-3239.243021780125\t0.8956750164180505\n 90:  ... loglikelihood=-3229.4058909613173\t0.8960502861431654\n 91:  ... loglikelihood=-3219.706619137626\t0.8963317384370016\n 92:  ... loglikelihood=-3210.1417459535037\t0.8965193732995591\n 93:  ... loglikelihood=-3200.7079342881884\t0.896894643024674\n 94:  ... loglikelihood=-3191.401964636446\t0.8971760953185102\n 95:  ... loglikelihood=-3182.220729798392\t0.8971760953185102\n 96:  ... loglikelihood=-3173.1612298590953\t0.8976451824749039\n 97:  ... loglikelihood=-3164.2205674396023\t0.8978328173374613\n 98:  ... loglikelihood=-3155.3959432017455\t0.8981142696312975\n 99:  ... loglikelihood=-3146.6846515914053\t0.8984895393564124\n100:  ... loglikelihood=-3138.084076805718\t0.8987709916502487\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "opennlp.tools.doccat.DoccatModel@3da304cf"
          },
          "metadata": {
          }
        }
      ]
    },
    {
      "metadata": {
      },
      "cell_type": "markdown",
      "source": "We can then use our model as follows:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sentences = ['OpenNLP is fantastic!',\n                 'Groovy is great fun!',\n                 'Math can be hard!']\ndef w = sentences*.size().max()\n\ndef categorizer = new DocumentCategorizerME(model)\nsentences.each {\n    def result = categorizer.categorize(it.split('[ !]'))\n    def category = categorizer.getBestCategory(result)\n    def prob = result[categorizer.getIndex(category)]\n    println \"${it.padRight(w)} $category (${ sprintf '%4.2f', prob})}\"\n}\nOutputCell.HIDDEN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "OpenNLP is fantastic! positive (0.64)}\nGroovy is great fun!  positive (0.74)}\nMath can be hard!     negative (0.61)}\n",
          "name": "stdout"
        }
      ]
    }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Groovy",
   "language": "groovy",
   "name": "groovy"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": ".groovy",
   "mimetype": "",
   "name": "Groovy",
   "nbconverter_exporter": "",
   "version": "2.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
