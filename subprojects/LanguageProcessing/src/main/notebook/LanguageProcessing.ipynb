{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Processing\n",
    "\n",
    "> **_NOTE:_** The examples may take a little while to run as they download the models each time.\n",
    "\n",
    "## Language detection\n",
    "\n",
    "We'll use [Apache OpenNLP](https://opennlp.apache.org/) to detect the likely language for some fragments of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c054b1-faea-497b-985a-1343e058c0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.opennlp opennlp-tools 1.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%import opennlp.tools.langdetect.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spa, fra, bul, dan]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base     = 'http://apache.forsale.plus/opennlp/models'\n",
    "url      = \"$base/langdetect/1.8.3/langdetect-183.bin\"\n",
    "model    = new LanguageDetectorModel(new URL(url))\n",
    "detector = new LanguageDetectorME(model)\n",
    "\n",
    "['Bienvenido a Madrid', 'Bienvenue à Paris',\n",
    " 'Добре дошли в София', 'Velkommen til København'].collect {\n",
    "    t -> detector.predictLanguage(t).lang\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Detection\n",
    "\n",
    "OpenNLP also supports sentence detection. We load the trained sentence detection model for English and use that to process some text. Even though the text has 28 full stops, only 4 of them are associated with the end of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The most referenced scientific paper of all time is \"Protein measurement with the\n",
       "Folin phenol reagent\" by Lowry, O. H., Rosebrough, N. J., Farr, A. L. & Randall,\n",
       "R. J. and was published in the J. BioChem. in 1951.\n",
       "\n",
       "It describes a method for\n",
       "measuring the amount of protein (even as small as 0.2 γ, were γ is the specific\n",
       "weight) in solutions and has been cited over 300,000 times and can be found here:\n",
       "https://www.jbc.org/content/193/1/265.full.pdf.\n",
       "\n",
       "Dr. Lowry completed\n",
       "two doctoral degrees under an M.D.-Ph.D. program from the University of Chicago\n",
       "before moving to Harvard under A. Baird Hastings.\n",
       "\n",
       "He was also the H.O.D of\n",
       "Pharmacology at Washington University in St. Louis for 29 years."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import opennlp.tools.sentdetect.*\n",
    "\n",
    "def text = '''\n",
    "The most referenced scientific paper of all time is \"Protein measurement with the\n",
    "Folin phenol reagent\" by Lowry, O. H., Rosebrough, N. J., Farr, A. L. & Randall,\n",
    "R. J. and was published in the J. BioChem. in 1951. It describes a method for\n",
    "measuring the amount of protein (even as small as 0.2 γ, were γ is the specific\n",
    "weight) in solutions and has been cited over 300,000 times and can be found here:\n",
    "https://www.jbc.org/content/193/1/265.full.pdf. Dr. Lowry completed\n",
    "two doctoral degrees under an M.D.-Ph.D. program from the University of Chicago\n",
    "before moving to Harvard under A. Baird Hastings. He was also the H.O.D of\n",
    "Pharmacology at Washington University in St. Louis for 29 years.\n",
    "'''\n",
    "\n",
    "base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "url      = \"$base/en-sent.bin\"\n",
    "\n",
    "def model = new SentenceModel(new URL(url))\n",
    "def detector = new SentenceDetectorME(model)\n",
    "def sentences = detector.sentDetect(text)\n",
    "assert text.count('.') == 28\n",
    "assert sentences.size() == 4\n",
    "sentences.join('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Detection\n",
    "\n",
    "Sometimes when analysing text we want to search for meaningful entities such as the dates, locations, names of people, etc. The following example uses OpenNLP. It has numerous named entity models which select such aspects individually. We'll use 5 English-language models: person, money, date, time, and location, but there are [other models and models for some other languages](http://opennlp.sourceforge.net/models-1.5/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading person ...\n",
      "Loading money ...\n",
      "Loading date ...\n",
      "Loading time ...\n",
      "Loading location ...\n",
      "A commit by person(Daniel Sun) on date(December 6, 2020) improved Groovy 4's language integrated query.\n",
      "A commit by person(Daniel) on Sun. date(December 6, 2020) improved Groovy 4's language integrated query.\n",
      "The Groovy in Action book by person(Dierk Koenig) et. al. is a bargain at money($50), or indeed any price.\n",
      "The conference wrapped up date(yesterday) at time(5:30 p.m.) in location(Copenhagen), location(Denmark).\n",
      "I saw Ms. person(May Smith) waving to person(June Jones).\n",
      "The parcel was passed from date(May to June).\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.namefind.*\n",
    "import opennlp.tools.tokenize.SimpleTokenizer\n",
    "import opennlp.tools.util.Span\n",
    "\n",
    "String[] sentences = [\n",
    "    \"A commit by Daniel Sun on December 6, 2020 improved Groovy 4's language integrated query.\",\n",
    "    \"A commit by Daniel on Sun. December 6, 2020 improved Groovy 4's language integrated query.\",\n",
    "    'The Groovy in Action book by Dierk Koenig et. al. is a bargain at $50, or indeed any price.',\n",
    "    'The conference wrapped up yesterday at 5:30 p.m. in Copenhagen, Denmark.',\n",
    "    'I saw Ms. May Smith waving to June Jones.',\n",
    "    'The parcel was passed from May to June.'\n",
    "]\n",
    "\n",
    "def base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "def modelNames = ['person', 'money', 'date', 'time', 'location']\n",
    "def finders = modelNames.collect{\n",
    "    println \"Loading $it ...\"\n",
    "    new NameFinderME(new TokenNameFinderModel(new URL((\"$base/en-ner-${it}.bin\"))))\n",
    "}\n",
    "\n",
    "def tokenizer = SimpleTokenizer.INSTANCE\n",
    "sentences.each { sentence ->\n",
    "    String[] tokens = tokenizer.tokenize(sentence)\n",
    "    Span[] tokenSpans = tokenizer.tokenizePos(sentence)\n",
    "    def entityText = [:]\n",
    "    def entityPos = [:]\n",
    "    finders.indices.each {fi ->\n",
    "        // could be made smarter by looking at probabilities and overlapping spans\n",
    "        Span[] spans = finders[fi].find(tokens)\n",
    "        spans.each{span ->\n",
    "            def se = span.start..<span.end\n",
    "            def pos = (tokenSpans[se.from].start)..<(tokenSpans[se.to].end)\n",
    "            entityPos[span.start] = pos\n",
    "            entityText[span.start] = \"$span.type(${sentence[pos]})\"\n",
    "        }\n",
    "    }\n",
    "    entityPos.keySet().toList().reverseEach {\n",
    "        def pos = entityPos[it]\n",
    "        def (from, to) = [pos.from, pos.to + 1]\n",
    "        sentence = sentence[0..<from] + entityText[it] + sentence[to..-1]\n",
    "    }\n",
    "    println sentence\n",
    "}\n",
    "OutputCell.HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech (POS) Detection\n",
    "\n",
    "Parts of speech (POS) detection tags words as nouns, verbs and other [parts-of-speed](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n",
    "Some of the common tags are:\n",
    "\n",
    "| Tag | Meaning |\n",
    "| --- | --- |\n",
    "| CC | coordinating conjunction |\n",
    "| CD | cardinal number |\n",
    "| DT | determiner |\n",
    "| IN | preposition or subordinating conjunction |\n",
    "| JJ | adjective |\n",
    "| JJR | adjective, comparative |\n",
    "| NN | noun, singular or mass |\n",
    "| NNS | noun, plural |\n",
    "| NNP | proper noun, singular |\n",
    "| POS | possessive ending |\n",
    "| PRP | personal pronoun |\n",
    "| PRP$ | possessive pronoun |\n",
    "| RB | adverb |\n",
    "| TO | the word \"to\" |\n",
    "| VB | verb, base form |\n",
    "| VBD | verb, past tense |\n",
    "| VBZ | verb, third person singular present |\n",
    "\n",
    "Here, we use OpenNLP's POS detection capabilities to detect the parts of speech for a nyumber of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP(Paul) VBZ(has) CD(two) NNS(sisters) , NNP(Maree) CC(and) NNP(Christine) .\n",
      "PRP$(His) NN(bark) VBD(was) RB(much) JJR(worse) IN(than) PRP$(his) NN(bite)\n",
      "VB(Turn) IN(on) DT(the) NNS(lights) TO(to) DT(the) NN(master) NN(bedroom)\n",
      "NN(Light) POS(') NN(em) DT(all) IN(up)\n",
      "VB(Make) PRP(it) JJ(dark) NN(downstairs)\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.postag.*\n",
    "import opennlp.tools.tokenize.SimpleTokenizer\n",
    "\n",
    "def base     = 'http://opennlp.sourceforge.net/models-1.5'\n",
    "def sentences = [\n",
    "    'Paul has two sisters, Maree and Christine.',\n",
    "    'His bark was much worse than his bite',\n",
    "    'Turn on the lights to the master bedroom',\n",
    "    \"Light 'em all up\",\n",
    "    'Make it dark downstairs'\n",
    "]\n",
    "def model = new POSModel(new URL((\"$base/en-pos-maxent.bin\")))\n",
    "def posTagger = new POSTaggerME(model)\n",
    "def tokenizer = SimpleTokenizer.INSTANCE\n",
    "sentences.each {\n",
    "    String[] tokens = tokenizer.tokenize(it)\n",
    "    String[] tags = posTagger.tag(tokens)\n",
    "    println tokens.indices.collect{tags[it] == tokens[it] ? tags[it] : \"${tags[it]}(${tokens[it]})\" }.join(' ')\n",
    "}\n",
    "OutputCell.HIDDEN"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Groovy",
   "language": "groovy",
   "name": "groovy"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": ".groovy",
   "mimetype": "",
   "name": "Groovy",
   "nbconverter_exporter": "",
   "version": "2.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
